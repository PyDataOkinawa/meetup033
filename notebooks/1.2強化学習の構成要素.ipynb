{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# これから使うやつら"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態\n",
    "\n",
    "状態集合$S$  \n",
    "$S = {s_1, s_2, \\dots, s_N}$\n",
    "\n",
    "例えば2x1に黒丸をおくゲームがあるとしたら、2x1（マスの数）x2(黒丸,無し)　= 4の状態数がある\n",
    "\n",
    "時間ステップ$t$における状態を表す確率変数を$S_t$とする.\n",
    "\n",
    "0ステップから順に状態を並べると$S_0,S_1,S_2,\\dots,S_t,\\dots$とかける.  \n",
    "このそれぞれは$s_1,s_2,\\dots,s_N$のうちのいずれかを指します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2x1マス x 2 = 4の状態集合\n",
    "S = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 行動\n",
    "\n",
    "行動集合$A(s)$  \n",
    "ある状態$s$において選択可能なすべての行動からのなる集合\n",
    "\n",
    "$A(s) = {a_1,a_2,\\dots,a_M}$\n",
    "\n",
    "この集合の要素を表す変数を$a$とする\n",
    "$(s)$が付いているのは状態によって要素の数が違う場合があるからです.\n",
    "\n",
    "時間ステップ$t$における行動を表す確率変数を$A_t$とする.\n",
    "$A_t$は、$A(S_t)$の要素のうち、いずれかの値をとる変数である.  \n",
    "0ステップから順に並べると$A_0,A_1,A_2,\\dots,A_t,\\dots$となる.\n",
    "\n",
    "このそれぞれは$a_1,a_2,\\dots,a_M$のいずれかを指します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = S[0]\n",
    "def A(s):\n",
    "    a = [0, 1, 2, 3]  # 行えるアクションの種類\n",
    "    if s == [0, 0]:\n",
    "        return a\n",
    "    else:\n",
    "        # 状態[0,0]以外は2,3しか行動できない\n",
    "        return a[2:]\n",
    "\n",
    "A(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 報酬\n",
    "\n",
    "$R$はすべての実数からなる集合とする. $S_t, A_t$および$S_{t+1}$に依存して定まる報酬を表す確率変数を$R_{t+1}$とする."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほい.\n",
    "\n",
    "状態・行動・報酬の３つの変数を導入して、相互作用の内容を表す準備はおｋ．（相互作用って？ -> エージェントと環境がお互いにやりとりすること\n",
    "\n",
    "これらを使って、マルコフ決定過程モデルを見ていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境について、初期時刻における状態 -> 初期状態を確率的に決定し、これをエージェントに渡します.\n",
    "時間ステップ0における状態$S_0$を数式で表すと.\n",
    "\n",
    "$S_0 \\sim P_{0}(s)$\n",
    "\n",
    "こうかける. $S_0$は時刻0での状態を表す確率変数、$P_0$は初期状態分布である。記号$\\sim$は左側に書かれた確率変数が、右側に書かれた確率分布に従った独立分布である.（よくわからんが、それ以外の変数に依存しない.ということ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルコフ決定過程のモデルにおいて、次の状態は、現在の状態と行動によって確率的に決定される.その確率はエージェントが状態$s$において行動$a$を決定した時、状態が状態$s'$に遷移する確率として\n",
    "\n",
    "$P(s'|s,a)$\n",
    "\n",
    "で与えられる.\n",
    "\n",
    "例えば、$t+1$ステップ目における状態$S_{t+1}$は、$t$ステップ目の状態$S_t$と、その状態で絵選ばれた行動を$A_t$としたとき\n",
    "\n",
    "$S_{t+1} \\sim P(s'|S_{t}A_{t})$\n",
    "\n",
    "に、よって定まることとなる. このとき、$S_{t+1}$は、$S_{t-1}$や、$A_{t-1}$などには依存せず、$S_t$と$A_t$のみに依存して定まることに注意が必要である。要は１つ前の情報を使うよって話ですよね.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たとえば、"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
